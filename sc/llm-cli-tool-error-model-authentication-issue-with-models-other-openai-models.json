[
  {
    "id": 632835,
    "name": "Siva.Meikanda Sivam",
    "username": "Meikanda_Sivam",
    "avatar_template": "/user_avatar/discourse.onlinedegree.iitm.ac.in/meikanda_sivam/{size}/67712_2.png",
    "created_at": "2025-05-28T16:16:14.815Z",
    "cooked": "<p>I Kindly need Help with LLM CLI Tool –  Model Authentication Issue with Models other OpenAI models.</p>\n<p>I’ve been trying to go a bit deeper into Module 1 after completing GA1, and I’ve encountered some issues while experimenting with the <code>llm</code> CLI tool and different models.</p>\n<p>Specifically, I tried running the following command to test the Gemini model, as shown on the Module 3 introduction page:</p>\n<pre><code class=\"lang-auto\">llm 'What is 2 + 2?' -m openrouter/google/gemini-2.0-flash-lite-001\n</code></pre>\n<p>But I received the following error:</p>\n<pre><code class=\"lang-auto\">Error: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n</code></pre>\n<p>Initially, I had set my OpenAI key from AIPipe , but I got a “model not found” error. So I checked the available models using:</p>\n<pre><code class=\"lang-auto\">llm model list\n</code></pre>\n<p>At that point, the Gemini model wasn’t listed.</p>\n<p>I then installed the <code>llm-openrouter</code> plugin, and after that, the Gemini model appeared in the list. However, I’m now facing the above authentication error.</p>\n<p>To test if the issue was only with Gemini and other models other than OpenAI models , I created a personal API key from OpenRouter and tried running a free model:(i tried free models on both keys from AIpipe and my personal account since it doesn’t need any credits to be purchased)</p>\n<pre><code class=\"lang-auto\">llm 'What is 2 + 2?' -m openrouter/qwen/qwen3-8b:free\n</code></pre>\n<p>This worked correctly with my OpenRouter API key, which confirms that the plugin is working fine.</p>\n<p>I’m confused about how to properly authenticate for other via AIPipe for OpenRouter using the <code>llm</code> CLI. I’ve been trying different approaches for the last two days but haven’t been able to resolve this.<br>\nCertainly! Here’s a grammatically correct and polished version of the message you want to add at the end:</p>\n<hr>\n<p>I also tried setting the API keys individually for OpenAI, OpenRouter(this is basically configured while installing the plugin <code>llm-openrouter</code>), and even my personal keys, using the key management options mentioned in the <code>llm</code> documentation. Additionally, I saw that our course page suggest changing the base URL like this:</p>\n<pre data-code-wrap=\"bash\"><code class=\"lang-bash\">export OPENAI_BASE_URL=https://aipipe.org/openrouter/v1\nllm 'What is 2 + 2?' -m openrouter/google/gemini-2.0-flash-lite-001\n</code></pre>\n<p>However, even this approach didn’t work for me.</p>\n<p>Could you kindly guide me on how to resolve this issue?</p>\n<p>Thank you for your time and help.</p>\n<p>Sincerely,<br>\n<strong>Meikanda Sivam</strong></p>",
    "post_number": 1,
    "post_type": 1,
    "posts_count": 1,
    "updated_at": "2025-05-28T20:28:12.023Z",
    "reply_count": 0,
    "reply_to_post_number": null,
    "quote_count": 0,
    "incoming_link_count": 0,
    "reads": 38,
    "readers_count": 37,
    "score": 6.0,
    "yours": false,
    "topic_id": 176603,
    "topic_slug": "llm-cli-tool-error-model-authentication-issue-with-models-other-openai-models",
    "display_username": "Siva.Meikanda Sivam",
    "primary_group_name": "ds-students",
    "flair_name": "ds-students",
    "flair_url": null,
    "flair_bg_color": "",
    "flair_color": "",
    "flair_group_id": 294,
    "badges_granted": [],
    "version": 1,
    "can_edit": false,
    "can_delete": false,
    "can_recover": false,
    "can_see_hidden_post": false,
    "can_wiki": false,
    "read": false,
    "user_title": null,
    "bookmarked": false,
    "actions_summary": [
      {
        "id": 2,
        "can_act": true
      }
    ],
    "moderator": false,
    "admin": false,
    "staff": false,
    "user_id": 21488,
    "hidden": false,
    "trust_level": 1,
    "deleted_at": null,
    "user_deleted": false,
    "edit_reason": null,
    "can_view_edit_history": true,
    "wiki": false,
    "post_url": "/t/llm-cli-tool-error-model-authentication-issue-with-models-other-openai-models/176603/1",
    "user_cakedate": "2023-09-18",
    "reactions": [],
    "current_user_reaction": null,
    "reaction_users_count": 0,
    "current_user_used_main_reaction": false,
    "can_accept_answer": false,
    "can_unaccept_answer": false,
    "accepted_answer": false,
    "topic_accepted_answer": null,
    "can_vote": false
  }
]